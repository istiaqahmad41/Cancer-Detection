# -*- coding: utf-8 -*-
"""True LNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gm5hnuJzaROR3LZSrGT-P-QGZz5Nh5E4
"""

# ============================
# 1. INSTALL REQUIREMENTS
# ============================
!pip install pytorch-lightning==2.0 torchmetrics seaborn matplotlib

# ============================
# 2. IMPORTS
# ============================
import os
import shutil
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torchvision.models import efficientnet_b0

import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, Callback

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
from PIL import Image

pl.seed_everything(42)

# ============================
# 3. DATASET & DATALOADER
# ============================
data_dir = "/content/dataset"

ip_dir = os.path.join(data_dir, '.ipynb_checkpoints')
if os.path.isdir(ip_dir):
    shutil.rmtree(ip_dir)

train_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),
    transforms.ToTensor(),
])

val_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
])

dataset = ImageFolder(data_dir, transform=train_transform)
class_names = dataset.classes

train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

# ============================
# 4. TRUE LIQUID NEURAL NETWORK
# ============================
class LiquidCell(nn.Module):
    def __init__(self, input_size, hidden_size):
        super().__init__()
        self.W_in = nn.Linear(input_size, hidden_size)
        self.W_rec = nn.Linear(hidden_size, hidden_size, bias=False)
        self.tau = nn.Linear(input_size, hidden_size)
        self.activation = nn.Tanh()

    def forward(self, x, h):
        tau = torch.sigmoid(self.tau(x)) + 1e-3
        dh = (-h + self.activation(self.W_in(x) + self.W_rec(h))) / tau
        h = h + dh
        return h


class LiquidLayer(nn.Module):
    def __init__(self, input_size, hidden_size, seq_len=6):
        super().__init__()
        self.cell = LiquidCell(input_size, hidden_size)
        self.hidden_size = hidden_size
        self.seq_len = seq_len

    def forward(self, x):
        B = x.size(0)
        h = torch.zeros(B, self.hidden_size, device=x.device)
        for _ in range(self.seq_len):
            h = self.cell(x, h)
        return h


class CNN_LNN(nn.Module):
    def __init__(self, num_classes, seq_len=6):
        super().__init__()

        base = efficientnet_b0(weights="IMAGENET1K_V1")
        self.cnn = nn.Sequential(*list(base.children())[:-1])
        cnn_out = 1280

        self.liquid = LiquidLayer(cnn_out, 256, seq_len)
        self.fc = nn.Linear(256, num_classes)

    def forward(self, x):
        x = self.cnn(x)
        x = x.squeeze(-1).squeeze(-1)  # B Ã— 1280
        h = self.liquid(x)
        return self.fc(h)

# ============================
# 5. PYTORCH LIGHTNING MODULE
# ============================
class LitModel(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.model = CNN_LNN(num_classes=len(class_names))
        self.loss_fn = nn.CrossEntropyLoss()

    def forward(self, x):
        return self.model(x)

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = self.loss_fn(y_hat, y)
        acc = (y_hat.argmax(1) == y).float().mean()

        self.log("train_loss", loss, prog_bar=True)
        self.log("train_acc", acc, prog_bar=True)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = self.loss_fn(y_hat, y)
        acc = (y_hat.argmax(1) == y).float().mean()

        self.log("val_loss", loss, prog_bar=True)
        self.log("val_acc", acc, prog_bar=True)

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, patience=2, factor=0.5
        )
        return {
            "optimizer": optimizer,
            "lr_scheduler": {"scheduler": scheduler, "monitor": "val_loss"},
        }

# ============================
# 6. TRAINING
# ============================
checkpoint = ModelCheckpoint(
    monitor="val_acc",
    mode="max",
    save_top_k=1,
    filename="best-model"
)

trainer = pl.Trainer(
    max_epochs=10,
    accelerator="gpu" if torch.cuda.is_available() else "cpu",
    callbacks=[checkpoint, LearningRateMonitor("epoch")]
)

model = LitModel()
trainer.fit(model, train_loader, val_loader)

# ============================
# 7. LOAD BEST MODEL
# ============================
best_model = LitModel.load_from_checkpoint(checkpoint.best_model_path)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
best_model.to(device)
best_model.eval()

# ============================
# 8. EVALUATION
# ============================
all_preds, all_labels = [], []

with torch.no_grad():
    for imgs, labels in val_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        preds = torch.argmax(best_model(imgs), 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

precision = precision_score(all_labels, all_preds, average=None)
recall = recall_score(all_labels, all_preds, average=None)
f1 = f1_score(all_labels, all_preds, average=None)

df_metrics = pd.DataFrame({
    "Class": class_names,
    "Precision": precision,
    "Recall": recall,
    "F1 Score": f1
})

print(df_metrics)

# ============================
# 9. CONFUSION MATRIX
# ============================
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d",
            xticklabels=class_names,
            yticklabels=class_names,
            cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# ============================
# 10. SINGLE IMAGE PREDICTION
# ============================
def predict_image(path):
    img = Image.open(path).convert("RGB")
    img = val_transform(img).unsqueeze(0).to(device)
    with torch.no_grad():
        pred = torch.argmax(best_model(img), 1).item()
    return class_names[pred]


